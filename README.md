> ğŸ“˜ Este README estÃ¡ em **PortuguÃªs-BR** pois o desafio foi entregue em portuguÃªs. Caso queira uma versÃ£o em inglÃªs, me avise!

![Go](https://img.shields.io/badge/Go-1.23-blue)
![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)

# ğŸŒ€ Magalu Cloud - Ingestor

Este projeto implementa o componente **Ingestor** do desafio tÃ©cnico do Magalu Cloud. Ele Ã© responsÃ¡vel por consumir mensagens de uso de produtos (pulses) via RabbitMQ, agregÃ¡-las temporariamente no Redis e posteriormente persistir os dados no PostgreSQL por meio de um cron worker.

---

## ğŸ“š SumÃ¡rio

- [ğŸ§  VisÃ£o Geral](#-visÃ£o-geral)
- [âš™ï¸ Tecnologias Utilizadas](#-tecnologias-utilizadas)
- [ğŸ“ Estrutura do Projeto](#-estrutura-do-projeto)
- [ğŸš€ Executando o Projeto](#-executando-o-projeto)
- [ğŸ§ª Executando os Testes](#-executando-os-testes)
- [ğŸ” Fluxo do Sistema](#-fluxo-do-sistema)
- [ğŸ§± Arquitetura](#-arquitetura)
- [ğŸ“Œ ConsideraÃ§Ãµes Finais](#-consideraÃ§Ãµes-finais)

---

## ğŸ§  VisÃ£o Geral

Este serviÃ§o Ã© composto por dois principais workers:

- `PulseTask` (Ingestor): Consome mensagens do RabbitMQ, agrega os dados por chave composta (tenant, SKU, unidade) e armazena temporariamente no Redis.
- `SavePulseTask`: A cada 1 hora, busca os dados agregados no Redis e persiste no PostgreSQL, limpando os dados do Redis apÃ³s a persistÃªncia com sucesso.

---

## âš™ï¸ Tecnologias Utilizadas

- **Go 1.23+**
- **RabbitMQ**
- **Redis**
- **PostgreSQL**
- **Docker & Docker Compose**
- **Logrus** (logger estruturado)
- **Gomock** (testes unitÃ¡rios)

---

## ğŸ“ Estrutura do Projeto

```bash
.
â”œâ”€â”€ cmd/                   # Ponto de entrada da aplicaÃ§Ã£o
â”‚   â”œâ”€â”€ worker/            # ConfiguraÃ§Ãµes dos workers (worker e cron worker)
â”‚   â”œâ”€â”€ simulator/         # ConfiguraÃ§Ãµes do simulator (Popula a fila com dados fakes e simula alto volume de dados)
â”‚   â”œâ”€â”€ api/               # ConfiguraÃ§Ãµes da api
â”œâ”€â”€ application/           # ContÃ©m a lÃ³gica de aplicaÃ§Ã£o
â”‚   â”œâ”€â”€ usecase/           # Casos de uso da aplicaÃ§Ã£o, focados em operaÃ§Ãµes especÃ­ficas do domÃ­nio.
â”‚   â”œâ”€â”€ service/           # ServiÃ§os que encapsulam integraÃ§Ãµes externas.
â”œâ”€â”€ domain/                # ContÃ©m os contratos e estruturas centrais da aplicaÃ§Ã£o
â”‚   â”œâ”€â”€ dto/               # Define os Data Transfer Objects, usados para transportar dados entre camadas da aplicaÃ§Ã£o.
â”‚   â”œâ”€â”€ entity/            # ContÃ©m as entidades de domÃ­nio, que representam os objetos persistidos no banco de dados.   
â”‚   â”œâ”€â”€ mapper/            # Realiza a conversÃ£o entre DTOs e Entities, garantindo o isolamento entre camadas.   
â”œâ”€â”€ infrastructure/        # ImplementaÃ§Ãµes tÃ©cnicas
â”‚   â”œâ”€â”€ database/          # ConfiguraÃ§Ãµes e conexÃµes com o bancos de dados.
â”‚   â”œâ”€â”€ repository/        # RepositÃ³rios com lÃ³gica de persistÃªncia no banco de dados.
â”œâ”€â”€ internal/              # CÃ³digo interno da aplicaÃ§Ã£o que nÃ£o deve ser exposto para uso externo.
â”‚   â”œâ”€â”€ configs/           # Leitura e organizaÃ§Ã£o das variÃ¡veis de ambiente. 
â”‚   â”œâ”€â”€ constants/         # Constantes reutilizadas no projeto.
â”‚   â”œâ”€â”€ dependency/        # InjeÃ§Ã£o de dependÃªncias e construÃ§Ã£o de componentes da aplicaÃ§Ã£o.
â”œâ”€â”€ utils/                 # FunÃ§Ãµes utilitÃ¡rias
â”œâ”€â”€ vendor/                # Pacotes externos baixados pelo Go Modules (go mod vendor), caso use vendoring.
â”œâ”€â”€ docker-compose.yml     # Subida dos serviÃ§os
â”œâ”€â”€ go.mod
â””â”€â”€ README.md
```

---

## ğŸš€ Executando o Projeto

> âš ï¸ **ObservaÃ§Ã£o:** Os comandos `make` utilizados neste README sÃ£o opcionais. Eles servem apenas para facilitar a execuÃ§Ã£o das tarefas mais comuns.
> 
> Se preferir (ou se estiver em um sistema que nÃ£o tenha `make` instalado), vocÃª pode executar os comandos diretamente via `go run`, `go test`, etc.
>
> ğŸ’¡ Dica: usuÃ¡rios Windows podem instalar `make` atravÃ©s do WSL, Chocolatey (`choco install make`) ou Git Bash.
>

1. **Clone o repositÃ³rio**

```bash
git clone https://github.com/seuusuario/pulse-ingestor.git
cd pulse-ingestor
```

2. **Configure as variavies de ambiente**

   - *Crie o arquivo `.env`*

    - *Pegue os exemplos do `.env.example`*
        
```bash
cp .env.example .env
```
        
   - *Preencha os campos com os valores desejados*

3. **Suba os serviÃ§os com Docker Compose**

```
    docker-compose up -d
```

Esse comando irÃ¡ iniciar:

- *`Redis`*
- *`RabbitMQ`*
- *`PostgreSQL`*
- *`AplicaÃ§Ã£o Go (main.go)`*

4. **Configurar e rodar o Script para popular a fila**

- *VocÃª pode configurar a taxa de envio, o nÃºmero de workers e os dados diretamente no script para testar concorrÃªncia e resiliÃªncia*.
- Altere as seguintes variaveis de ambiente para:

```bash
    SIMULATOR_TOTAL_MESSAGES=1000     #define o nÃºmero de mensagens simuladas que vamos enviar para a fila 
    SIMULATOR_WORKERS_NUMBER=10       #/define o nÃºmero de workers que vÃ£o realizar o processo de envio de mensagens
    SIMULATOR_BUFFER_SIZE=100         #define o tamanho do buffer para o envio das mensagens
```

- Rode o seguinte comando para comeÃ§ar a popular a fila com os dados fake:

  `Make run-script`

  ou se preferir:

  `go run main.go -script`

5. **Configurar e rodar o Worker para execuÃ§Ã£o do serviÃ§o**

- ApÃ³s a fila estar populada, deve rodar o seguinte comando para execuÃ§Ã£o do serviÃ§o:

  `Make run-worker`

  ou se preferir:

  `go run main.go -worker`

## ğŸ§ª Executando os Testes

- VocÃª pode rodar todos os testes com:

  `Make test`

  ou se preferir:

  `go test ./... -v`

- Para acompanhar a cobertura de testes rode o comando:

  `Make coverage`
  
- **Os testes cobrem os fluxos de sucesso e falha dos workers,usecases ,repositorys, simulaÃ§Ãµes de falhas no Redis e mensagens invÃ¡lidas no RabbitMQ.**

## ğŸ” Fluxo do Sistema

- **IngestÃ£o**

    - Mensagens sÃ£o consumidas do RabbitMQ por workers concorrentes.

    - Cada mensagem Ã© desserializada e agregada em Redis usando chave composta.

- **PersistÃªncia**

    - Um cron job executa periodicamente (1h) a leitura das chaves agregadas no Redis.

    - Os dados sÃ£o salvos em lote no PostgreSQL.

    - ApÃ³s a persistÃªncia, as chaves correspondentes sÃ£o removidas do Redis.

```bash
flowchart TD
    A = [Recebe mensagem via RabbitMQ] --> B [Parse JSON e validaÃ§Ã£o]
    B --> C [Agrega dados no Redis]
    C --> D [Worker salva no Redis]
    E [Cron job a cada 1h] --> F [LÃª agregados do Redis]
    F --> G [Persiste no PostgreSQL]
    G --> H [Limpa Redis apÃ³s sucesso]
```

## ğŸ§± Arquitetura

- A aplicaÃ§Ã£o segue princÃ­pios da `Clean Architecture`, separando responsabilidades em camadas:

  - **Domain:** interfaces e contratos
  - **Application:** lÃ³gica de negÃ³cio pura
  - **Infrastructure:** detalhes tÃ©cnicos (drivers, clients)
  - **CMD:** ponto de entrada da aplicaÃ§Ã£o
  - **Internal:** implementaÃ§Ãµes internas
  - **Utils:** funÃ§Ãµes auxiliares reutilizÃ¡veis

- BenefÃ­cios:

  - FÃ¡cil testabilidade
  - Alta manutenibilidade
  - IndependÃªncia de frameworks e ferramentas

## ğŸ“Œ ConsideraÃ§Ãµes Finais

- âœ… AplicaÃ§Ã£o resiliente com `retries` e `backoff` no Redis

- âœ… Logs estruturados com `logrus`

- âœ… `Testes unitÃ¡rios` com cobertura dos principais fluxos

- âœ… Pronta para rodar com `docker-compose up`

- Desenvolvido com ğŸ’™ para o desafio tÃ©cnico do Magalu Cloud.

## ğŸ“„ LicenÃ§a

- Este projeto estÃ¡ licenciado sob os termos da [MIT License](LICENSE).

---
